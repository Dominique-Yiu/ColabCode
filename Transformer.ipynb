{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMBId9nPOS5Uocf3eDjUxf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dominique-Yiu/ColabCode/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Realization\n",
        "**Transformer Architecture** \\\n",
        "1. Encoder\n",
        "- Input words embedding\n",
        "  - Turn the sparse one-hot vector into the dense contiguouly vector by FFN without bias.\n",
        "- Position encoding\n",
        "- Multi-head self-attention\n",
        "- Feed-forword network\n",
        "2. Decoder\n",
        "- Output words embedding\n",
        "- Masked multi-head self-attention\n",
        "- Multi-head cross-attention\n",
        "- Feed-forword network\n",
        "- Softmax"
      ],
      "metadata": {
        "id": "_U-F1ziytKW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "实现的难点： \\\n",
        "1. Word Embedding\n",
        "2. Posotion Embedding\n",
        "3. Encoder self-attention mask\n",
        "4. Intra-attention ask\n",
        "5. Decoder self-attention mask\n",
        "6. Multi-head self-attention"
      ],
      "metadata": {
        "id": "1KRkyaXtEn7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TYbEqVzHtIHm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "# the size of the word sheet\n",
        "max_num_src_words = 8\n",
        "max_num_tgt_words = 8\n",
        "# \n",
        "model_dim = 8\n",
        "# the max length of sequence\n",
        "max_src_seq_len = 5\n",
        "max_tgt_seq_len = 5\n",
        "# 位置索引最大值\n",
        "max_position_len = 5\n",
        "# generate the sequence length randomly, its size is fixed\n",
        "# src_len = torch.randint(2, 5, (batch_size,))\n",
        "# tgt_len = torch.randint(2, 5, (batch_size,))\n",
        "src_len = torch.Tensor([2, 4]).to(torch.int32)\n",
        "tgt_len = torch.Tensor([4, 3]).to(torch.int32)\n",
        "\n",
        "# generate the src/tgt sentence, and pad this sentence with default value '0'\n",
        "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_src_words, (L,)), (0, max(src_len) - L)), 0) \\\n",
        "           for L in src_len])\n",
        "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_tgt_words, (L,)), (0, max(tgt_len) - L)), 0) \\\n",
        "           for L in tgt_len])\n",
        "\n",
        "\"\"\"Word Embedding\"\"\"\n",
        "# 构造 Word Embedding\n",
        "src_embedding_table = nn.Embedding(max_num_src_words + 1, model_dim)\n",
        "tgt_embedding_table = nn.Embedding(max_num_tgt_words + 1, model_dim)\n",
        "src_embedding = src_embedding_table(src_seq)\n",
        "tgt_embedding = tgt_embedding_table(tgt_seq)\n",
        "\n",
        "print(src_embedding_table.weight)\n",
        "print(src_seq)\n",
        "print(src_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_gW7RHHwOEr",
        "outputId": "ddca86c3-be8a-4266-a65c-4ea6eb27f2da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-1.6669, -0.0190, -0.7397, -1.3589,  2.0105, -1.5195,  0.5483,  1.6877],\n",
            "        [ 1.1968,  1.3093,  0.6002,  1.9838, -0.0909, -0.1004, -0.9728, -1.9918],\n",
            "        [ 0.7387, -1.4952, -0.6838,  0.4220, -0.0895,  0.9863, -0.8907,  0.8737],\n",
            "        [ 0.3023,  0.0844,  0.0841, -0.2829, -0.6646,  0.1810, -0.9762, -0.4892],\n",
            "        [ 0.9160,  0.2793, -0.3699,  0.3383, -0.4026, -1.5498,  0.4681,  0.0609],\n",
            "        [ 0.3499, -0.4947, -1.4099,  1.2324, -1.1353,  0.0489,  0.1097,  0.1956],\n",
            "        [-1.2591,  0.7273,  1.1955, -1.2456,  1.9668, -0.3416,  1.0928, -0.7418],\n",
            "        [ 1.8613, -0.2107, -1.4659,  1.0338,  0.1964, -1.6763, -1.9309, -0.3148],\n",
            "        [ 0.4745,  0.8303, -1.2484, -1.9925, -0.8226,  0.4716, -1.0549,  0.7839]],\n",
            "       requires_grad=True)\n",
            "tensor([[7, 7, 0, 0],\n",
            "        [4, 2, 6, 2]])\n",
            "tensor([[[ 1.8613, -0.2107, -1.4659,  1.0338,  0.1964, -1.6763, -1.9309,\n",
            "          -0.3148],\n",
            "         [ 1.8613, -0.2107, -1.4659,  1.0338,  0.1964, -1.6763, -1.9309,\n",
            "          -0.3148],\n",
            "         [-1.6669, -0.0190, -0.7397, -1.3589,  2.0105, -1.5195,  0.5483,\n",
            "           1.6877],\n",
            "         [-1.6669, -0.0190, -0.7397, -1.3589,  2.0105, -1.5195,  0.5483,\n",
            "           1.6877]],\n",
            "\n",
            "        [[ 0.9160,  0.2793, -0.3699,  0.3383, -0.4026, -1.5498,  0.4681,\n",
            "           0.0609],\n",
            "         [ 0.7387, -1.4952, -0.6838,  0.4220, -0.0895,  0.9863, -0.8907,\n",
            "           0.8737],\n",
            "         [-1.2591,  0.7273,  1.1955, -1.2456,  1.9668, -0.3416,  1.0928,\n",
            "          -0.7418],\n",
            "         [ 0.7387, -1.4952, -0.6838,  0.4220, -0.0895,  0.9863, -0.8907,\n",
            "           0.8737]]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Position Embedding\"\"\"\n",
        "# 构造Position Embedding\n",
        "pos_mat  =  torch.arange(max_position_len).reshape((-1, 1))\n",
        "i_mat = torch.pow(10000, torch.arange(0, 8, 2).reshape((1, -1)) / model_dim)\n",
        "pe_embedding_table = torch.zeros(max_position_len, model_dim)\n",
        "pe_embedding_table[:, 0::2] = torch.sin(pos_mat / i_mat)\n",
        "pe_embedding_table[:, 1::2] = torch.cos(pos_mat / i_mat)\n",
        "\n",
        "pe_embedding = nn.Embedding(max_position_len, model_dim)\n",
        "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad = False)\n",
        "src_pos = torch.cat([torch.unsqueeze(torch.arange(max(src_len)), 0) for _ in src_len]).to(torch.int32)\n",
        "tgt_pos = torch.cat([torch.unsqueeze(torch.arange(max(tgt_len)), 0) for _ in tgt_len]).to(torch.int32)\n",
        "\n",
        "src_pos_embedding = pe_embedding(src_pos)\n",
        "tgt_pos_embedding = pe_embedding(tgt_pos)\n",
        "print(src_pos_embedding)\n",
        "print(tgt_pos_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryUZJMKGxHOW",
        "outputId": "6aef4a5c-5a93-42c2-bffc-18df43c8dfae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
            "           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
            "           9.9955e-01,  3.0000e-03,  1.0000e+00]]])\n",
            "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
            "           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
            "           9.9955e-01,  3.0000e-03,  1.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\"\"\"Encoder: Self-Attention Mask\"\"\"\n",
        "# 构造encoder的self-attention mask\n",
        "# mask的shape: [batch_size, max_src_len, max_src_len]，数值为1/-inf\n",
        "valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(src_len) - L)), 0) for L in src_len]), 2)\n",
        "valid_encoder_pos_matrix = torch.bmm(valid_encoder_pos, valid_encoder_pos.transpose(1, 2))\n",
        "invalid_encoder_pos_matrix = 1 - valid_encoder_pos_matrix\n",
        "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)\n",
        "score = torch.randn(batch_size, max(src_len), max(src_len))\n",
        "masked_score = score.masked_fill(mask_encoder_self_attention, -1e9)\n",
        "prob = F.softmax(masked_score, -1)\n",
        "\n",
        "print(score)\n",
        "print(masked_score)\n",
        "print(prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "towG0uO6-rPP",
        "outputId": "e8723bea-f878-47a7-e8f0-7802ffb013ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.7272,  1.8509,  1.3269,  0.5349],\n",
            "         [ 2.4649, -0.9675, -0.8312, -0.7691],\n",
            "         [-0.6841,  0.6586, -0.1978, -1.0875],\n",
            "         [-0.3524, -1.1417,  0.4297,  0.7176]],\n",
            "\n",
            "        [[ 0.2645, -0.4864, -1.2504, -0.4116],\n",
            "         [-0.1779, -0.0664,  0.5948,  0.3009],\n",
            "         [-0.3937,  0.3348,  0.5173,  0.3991],\n",
            "         [ 1.9093, -0.8432, -0.1482,  0.0304]]])\n",
            "tensor([[[ 7.2721e-01,  1.8509e+00, -1.0000e+09, -1.0000e+09],\n",
            "         [ 2.4649e+00, -9.6753e-01, -1.0000e+09, -1.0000e+09],\n",
            "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "        [[ 2.6455e-01, -4.8645e-01, -1.2504e+00, -4.1157e-01],\n",
            "         [-1.7793e-01, -6.6429e-02,  5.9476e-01,  3.0092e-01],\n",
            "         [-3.9373e-01,  3.3476e-01,  5.1728e-01,  3.9905e-01],\n",
            "         [ 1.9093e+00, -8.4321e-01, -1.4817e-01,  3.0356e-02]]])\n",
            "tensor([[[0.2453, 0.7547, 0.0000, 0.0000],\n",
            "         [0.9687, 0.0313, 0.0000, 0.0000],\n",
            "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "         [0.2500, 0.2500, 0.2500, 0.2500]],\n",
            "\n",
            "        [[0.4545, 0.2145, 0.0999, 0.2311],\n",
            "         [0.1696, 0.1896, 0.3672, 0.2737],\n",
            "         [0.1287, 0.2667, 0.3201, 0.2844],\n",
            "         [0.7439, 0.0474, 0.0950, 0.1136]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "以上主要实现了词向量，位置编码，编码器子注意力的掩码"
      ],
      "metadata": {
        "id": "B0NgCEIZTo3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Corss-Attention\"\"\"\n",
        "# Q @ K^T shape: [batch_size, tht_seq_len, src_seq_len]\n",
        "valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(src_len) - L)), 0) for L in src_len]), 2)\n",
        "valid_decoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(tgt_len) - L)), 0) for L in tgt_len]), 2)\n",
        "# 目标序列位置对原始序列的关系（有效性）\n",
        "valid_cross_pos_matrix = torch.bmm(valid_encoder_pos, valid_decoder_pos.transpose(1, 2))\n",
        "invalid_cross_pos_matrix = 1 - valid_cross_pos_matrix\n",
        "mask_cross_attention = invalid_cross_pos_matrix.to(torch.bool)\n",
        "score = torch.randn(batch_size, max(tgt_len), max(src_len))\n",
        "masked_score = score.masked_fill(mask_cross_attention, -1e9)\n",
        "prob = F.softmax(masked_score, -1)\n",
        "\n",
        "print(valid_encoder_pos)\n",
        "print(valid_decoder_pos)\n",
        "print(valid_cross_pos_matrix)\n",
        "print(masked_score)\n",
        "print(prob)"
      ],
      "metadata": {
        "id": "9uQ1UWZqNw7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0359183-72ca-4c7d-bc68-485be916cf35"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.],\n",
            "         [1.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[1.],\n",
            "         [1.],\n",
            "         [1.],\n",
            "         [1.]]])\n",
            "tensor([[[1.],\n",
            "         [1.],\n",
            "         [1.],\n",
            "         [1.]],\n",
            "\n",
            "        [[1.],\n",
            "         [1.],\n",
            "         [1.],\n",
            "         [0.]]])\n",
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 1., 1., 0.],\n",
            "         [1., 1., 1., 0.],\n",
            "         [1., 1., 1., 0.],\n",
            "         [1., 1., 1., 0.]]])\n",
            "tensor([[[-2.7826e-01, -1.8842e+00, -1.0313e+00, -1.6518e-01],\n",
            "         [-1.5267e+00,  1.0573e-01, -1.5322e+00,  2.0614e-01],\n",
            "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "        [[ 1.3311e-01,  2.7074e+00,  5.1707e-01, -1.0000e+09],\n",
            "         [ 1.5017e+00, -5.1609e-01,  8.0322e-01, -1.0000e+09],\n",
            "         [ 1.5498e+00,  8.3718e-02,  7.6715e-01, -1.0000e+09],\n",
            "         [-2.6354e-01, -2.0937e-01,  7.5223e-01, -1.0000e+09]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Decoder Self-Attention Mask\"\"\"\n",
        "# 因果Mask\n",
        "valid_decoder_tri_matrix = torch.cat([torch.unsqueeze(F.pad(torch.tril(torch.ones((L, L))), (0, max(tgt_len) - L, 0, max(tgt_len) - L)), 0) for L in tgt_len])\n",
        "invalid_decoder_tri_matrix = 1 - valid_decoder_tri_matrix\n",
        "mask_invalid_decoder_tri_matrix = invalid_decoder_tri_matrix.to(torch.bool)\n",
        "\n",
        "score = torch.randn(batch_size, max(tgt_len), max(tgt_len))\n",
        "masked_score = score.masked_fill(mask_invalid_decoder_tri_matrix, -1e9)\n",
        "prob = F.softmax(masked_score, -1)\n",
        "print(tgt_len)\n",
        "print(prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9-7cFfNGUIO",
        "outputId": "9293ed56-226f-4b23-f56a-6647a822c603"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 3], dtype=torch.int32)\n",
            "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1625, 0.8375, 0.0000, 0.0000],\n",
            "         [0.1744, 0.1313, 0.6943, 0.0000],\n",
            "         [0.1704, 0.4480, 0.0531, 0.3285]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.6037, 0.3963, 0.0000, 0.0000],\n",
            "         [0.3056, 0.2307, 0.4637, 0.0000],\n",
            "         [0.2500, 0.2500, 0.2500, 0.2500]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_k}})V$"
      ],
      "metadata": {
        "id": "aAJicY_pMkJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Scaled Self-Attention\"\"\"\n",
        "def scaled_dot_product_attention(Q, K, V, attn_mask):\n",
        "  score = torch.bmm(Q, K.transpose(-2, -1)) / torch.sqrt(model_dim)\n",
        "  masked_score = torch.masked_fill(score * attn_mask, -1e9)\n",
        "  prob = F.softmax(masked_score, -1)\n",
        "  context = torch.bmm(prob, V)\n",
        "  return context"
      ],
      "metadata": {
        "id": "0d3xYZgjKkH-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}