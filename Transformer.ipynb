{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWak1+gpWHSJHvqYnhcSTb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dominique-Yiu/ColabCode/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Realization\n",
        "**Transformer Architecture** \\\n",
        "1. Encoder\n",
        "- Input words embedding\n",
        "  - Turn the sparse one-hot vector into the dense contiguouly vector by FFN without bias.\n",
        "- Position encoding\n",
        "- Multi-head self-attention\n",
        "- Feed-forword network\n",
        "2. Decoder\n",
        "- Output words embedding\n",
        "- Masked multi-head self-attention\n",
        "- Multi-head cross-attention\n",
        "- Feed-forword network\n",
        "- Softmax"
      ],
      "metadata": {
        "id": "_U-F1ziytKW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "实现的难点： \\\n",
        "1. Word Embedding\n",
        "2. Posotion Embedding\n",
        "3. Encoder self-attention mask\n",
        "4. Intra-attention ask\n",
        "5. Decoder self-attention mask\n",
        "6. Multi-head self-attention"
      ],
      "metadata": {
        "id": "1KRkyaXtEn7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYbEqVzHtIHm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "# the size of the word sheet\n",
        "max_num_src_words = 8\n",
        "max_num_tgt_words = 8\n",
        "# \n",
        "model_dim = 8\n",
        "# the max length of sequence\n",
        "max_src_seq_len = 5\n",
        "max_tgt_seq_len = 5\n",
        "# 位置索引最大值\n",
        "max_position_len = 5\n",
        "# generate the sequence length randomly, its size is fixed\n",
        "# src_len = torch.randint(2, 5, (batch_size,))\n",
        "# tgt_len = torch.randint(2, 5, (batch_size,))\n",
        "src_len = torch.Tensor([2, 4]).to(torch.int32)\n",
        "tgt_len = torch.Tensor([4, 3]).to(torch.int32)\n",
        "\n",
        "# generate the src/tgt sentence, and pad this sentence with default value '0'\n",
        "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_src_words, (L,)), (0, max(src_len) - L)), 0) \\\n",
        "           for L in src_len])\n",
        "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_tgt_words, (L,)), (0, max(tgt_len) - L)), 0) \\\n",
        "           for L in tgt_len])\n",
        "\n",
        "\"\"\"Word Embedding\"\"\"\n",
        "# 构造 Word Embedding\n",
        "src_embedding_table = nn.Embedding(max_num_src_words + 1, model_dim)\n",
        "tgt_embedding_table = nn.Embedding(max_num_tgt_words + 1, model_dim)\n",
        "src_embedding = src_embedding_table(src_seq)\n",
        "tgt_embedding = tgt_embedding_table(tgt_seq)\n",
        "\n",
        "print(src_embedding_table.weight)\n",
        "print(src_seq)\n",
        "print(src_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_gW7RHHwOEr",
        "outputId": "767fb66c-5104-41db-a183-40aae5c68a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 1.3525, -0.4454,  1.6057,  0.0904, -0.6940, -1.2095, -1.9863, -1.7586],\n",
            "        [-0.6995, -0.6308,  0.6180, -0.7553,  2.1051,  0.4115, -0.8706, -0.7519],\n",
            "        [ 1.7582,  1.5953, -1.1571, -0.7387, -0.3730, -0.2318, -1.1671,  1.8609],\n",
            "        [-1.0063, -1.6284, -1.3913,  2.3693,  0.7328, -0.9040,  0.3566, -0.5074],\n",
            "        [-0.5125,  1.3462, -0.2684,  0.1615,  0.8660, -0.5704, -1.0948,  1.6697],\n",
            "        [ 0.7128, -0.2651, -0.4819, -0.4780,  2.1755,  0.4100, -0.7463, -1.3425],\n",
            "        [ 0.0381,  1.3084, -0.6551, -1.2019,  1.9547, -0.8416, -0.3264,  0.1672],\n",
            "        [ 0.3851,  0.8669,  1.4315, -0.7066, -2.2423, -0.7346,  1.0852, -0.4502],\n",
            "        [ 0.2387, -0.4505, -0.8245, -0.3745,  0.3566,  0.3393, -0.4981,  0.4199]],\n",
            "       requires_grad=True)\n",
            "tensor([[1, 6, 0, 0],\n",
            "        [1, 3, 2, 6]])\n",
            "tensor([[[-0.6995, -0.6308,  0.6180, -0.7553,  2.1051,  0.4115, -0.8706,\n",
            "          -0.7519],\n",
            "         [ 0.0381,  1.3084, -0.6551, -1.2019,  1.9547, -0.8416, -0.3264,\n",
            "           0.1672],\n",
            "         [ 1.3525, -0.4454,  1.6057,  0.0904, -0.6940, -1.2095, -1.9863,\n",
            "          -1.7586],\n",
            "         [ 1.3525, -0.4454,  1.6057,  0.0904, -0.6940, -1.2095, -1.9863,\n",
            "          -1.7586]],\n",
            "\n",
            "        [[-0.6995, -0.6308,  0.6180, -0.7553,  2.1051,  0.4115, -0.8706,\n",
            "          -0.7519],\n",
            "         [-1.0063, -1.6284, -1.3913,  2.3693,  0.7328, -0.9040,  0.3566,\n",
            "          -0.5074],\n",
            "         [ 1.7582,  1.5953, -1.1571, -0.7387, -0.3730, -0.2318, -1.1671,\n",
            "           1.8609],\n",
            "         [ 0.0381,  1.3084, -0.6551, -1.2019,  1.9547, -0.8416, -0.3264,\n",
            "           0.1672]]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Position Embedding\"\"\"\n",
        "# 构造Position Embedding\n",
        "pos_mat  =  torch.arange(max_position_len).reshape((-1, 1))\n",
        "i_mat = torch.pow(10000, torch.arange(0, 8, 2).reshape((1, -1)) / model_dim)\n",
        "pe_embedding_table = torch.zeros(max_position_len, model_dim)\n",
        "pe_embedding_table[:, 0::2] = torch.sin(pos_mat / i_mat)\n",
        "pe_embedding_table[:, 1::2] = torch.cos(pos_mat / i_mat)\n",
        "\n",
        "pe_embedding = nn.Embedding(max_position_len, model_dim)\n",
        "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad = False)\n",
        "src_pos = torch.cat([torch.unsqueeze(torch.arange(max(src_len)), 0) for _ in src_len]).to(torch.int32)\n",
        "tgt_pos = torch.cat([torch.unsqueeze(torch.arange(max(tgt_len)), 0) for _ in tgt_len]).to(torch.int32)\n",
        "\n",
        "src_pos_embedding = pe_embedding(src_pos)\n",
        "tgt_pos_embedding = pe_embedding(tgt_pos)\n",
        "print(src_pos_embedding)\n",
        "print(tgt_pos_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryUZJMKGxHOW",
        "outputId": "e64abf7c-da45-4a8c-cedb-5aa2b63851cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
            "           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
            "           9.9955e-01,  3.0000e-03,  1.0000e+00]]])\n",
            "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
            "           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
            "           9.9955e-01,  3.0000e-03,  1.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\"\"\"Encoder: Self-Attention Mask\"\"\"\n",
        "# 构造encoder的self-attention mask\n",
        "# mask的shape: [batch_size, max_src_len, max_src_len]，数值为1/-inf\n",
        "valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(src_len) - L)), 0) for L in src_len]), 2)\n",
        "valid_encoder_pos_matrix = torch.bmm(valid_encoder_pos, valid_encoder_pos.transpose(1, 2))\n",
        "invalid_encoder_pos_matrix = 1 - valid_encoder_pos_matrix\n",
        "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)\n",
        "score = torch.randn(batch_size, max(src_len), max(src_len))\n",
        "masked_score = score.masked_fill(mask_encoder_self_attention, -1e9)\n",
        "prob = F.softmax(masked_score, -1)\n",
        "\n",
        "print(score)\n",
        "print(masked_score)\n",
        "print(prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "towG0uO6-rPP",
        "outputId": "6d08bfd5-1c94-4e97-f139-3b7a98aa46df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.7397, -0.5672,  1.3452, -0.3177],\n",
            "         [-0.4246,  1.7285,  0.1224, -0.8866],\n",
            "         [ 0.7788, -1.4620,  1.6338, -0.9117],\n",
            "         [-0.8076, -0.8892, -1.3644, -1.0709]],\n",
            "\n",
            "        [[ 1.6645,  1.1345, -0.1216, -1.1251],\n",
            "         [-0.7066,  0.6371,  1.2838,  1.0437],\n",
            "         [ 0.1213, -1.7839,  0.8772,  0.6051],\n",
            "         [-1.6138,  1.5712, -1.2977,  2.5202]]])\n",
            "tensor([[[ 1.7397e+00, -5.6720e-01, -1.0000e+09, -1.0000e+09],\n",
            "         [-4.2460e-01,  1.7285e+00, -1.0000e+09, -1.0000e+09],\n",
            "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "        [[ 1.6645e+00,  1.1345e+00, -1.2160e-01, -1.1251e+00],\n",
            "         [-7.0658e-01,  6.3712e-01,  1.2838e+00,  1.0437e+00],\n",
            "         [ 1.2126e-01, -1.7839e+00,  8.7725e-01,  6.0507e-01],\n",
            "         [-1.6138e+00,  1.5712e+00, -1.2977e+00,  2.5202e+00]]])\n",
            "tensor([[[0.9094, 0.0906, 0.0000, 0.0000],\n",
            "         [0.1040, 0.8960, 0.0000, 0.0000],\n",
            "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "         [0.2500, 0.2500, 0.2500, 0.2500]],\n",
            "\n",
            "        [[0.5502, 0.3238, 0.0922, 0.0338],\n",
            "         [0.0558, 0.2141, 0.4087, 0.3214],\n",
            "         [0.2041, 0.0304, 0.4346, 0.3310],\n",
            "         [0.0112, 0.2716, 0.0154, 0.7017]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "以上主要实现了词向量，位置编码，编码器子注意力的掩码"
      ],
      "metadata": {
        "id": "B0NgCEIZTo3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Corss-Attention\"\"\"\n",
        "# Q @ K^T shape: [batch_size, tht_seq_len, src_seq_len]\n",
        "valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(src_len) - L)), 0) for L in src_len]), 2)\n",
        "valid_decoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(tgt_len) - L)), 0) for L in tgt_len]), 2)\n",
        "# 目标序列位置对原始序列的关系（有效性）\n",
        "valid_cross_pos_matrix = torch.bmm(valid_encoder_pos, valid_decoder_pos.transpose(1, 2))\n",
        "invalid_cross_pos_matrix = 1 - valid_cross_pos_matrix\n",
        "mask_cross_attention = invalid_cross_pos_matrix.to(torch.bool)\n",
        "score = torch.randn(batch_size, max(tgt_len), max(src_len))\n",
        "masked_score = score.masked_fill(mask_cross_attention, -1e9)\n",
        "prob = F.softmax(masked_score, -1)\n",
        "\n",
        "print(valid_encoder_pos)\n",
        "print(valid_decoder_pos)\n",
        "print(valid_cross_pos_matrix)\n",
        "print(masked_score)\n",
        "print(prob)"
      ],
      "metadata": {
        "id": "9uQ1UWZqNw7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797b829e-34a6-4b0b-d773-47500902c697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.],\n",
            "         [1.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[1.],\n",
            "         [1.],\n",
            "         [1.],\n",
            "         [1.]]])\n",
            "tensor([[[1.],\n",
            "         [1.],\n",
            "         [1.],\n",
            "         [1.]],\n",
            "\n",
            "        [[1.],\n",
            "         [1.],\n",
            "         [1.],\n",
            "         [0.]]])\n",
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 1., 1., 0.],\n",
            "         [1., 1., 1., 0.],\n",
            "         [1., 1., 1., 0.],\n",
            "         [1., 1., 1., 0.]]])\n",
            "tensor([[[ 9.2010e-01, -9.7814e-01, -1.2373e+00, -5.1125e-01],\n",
            "         [ 6.7158e-01, -1.3036e+00, -6.0340e-01,  6.7199e-01],\n",
            "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "        [[-1.6189e-01,  1.2645e-01, -1.0282e-02, -1.0000e+09],\n",
            "         [ 2.8165e-01,  1.7807e+00,  1.8699e-02, -1.0000e+09],\n",
            "         [ 2.4964e+00,  4.9022e-01, -4.9626e-01, -1.0000e+09],\n",
            "         [-1.3185e+00,  4.3000e-01, -1.3165e+00, -1.0000e+09]]])\n",
            "tensor([[[0.6647, 0.0996, 0.0769, 0.1589],\n",
            "         [0.4135, 0.0574, 0.1155, 0.4136],\n",
            "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "         [0.2500, 0.2500, 0.2500, 0.2500]],\n",
            "\n",
            "        [[0.2859, 0.3814, 0.3327, 0.0000],\n",
            "         [0.1601, 0.7168, 0.1231, 0.0000],\n",
            "         [0.8441, 0.1135, 0.0423, 0.0000],\n",
            "         [0.1291, 0.7416, 0.1293, 0.0000]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Decoder Self-Attention Mask\"\"\"\n",
        "# 因果Mask\n",
        "valid_decoder_tri_matrix = torch.cat([torch.unsqueeze(F.pad(torch.tril(torch.ones((L, L))), (0, max(tgt_len) - L, 0, max(tgt_len) - L)), 0) for L in tgt_len])\n",
        "invalid_decoder_tri_matrix = 1 - valid_decoder_tri_matrix\n",
        "mask_invalid_decoder_tri_matrix = invalid_decoder_tri_matrix.to(torch.bool)\n",
        "\n",
        "score = torch.randn(batch_size, max(tgt_len), max(tgt_len))\n",
        "masked_score = score.masked_fill(mask_invalid_decoder_tri_matrix, -1e9)\n",
        "prob = F.softmax(masked_score, -1)\n",
        "print(tgt_len)\n",
        "print(prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9-7cFfNGUIO",
        "outputId": "4501886e-5eee-440c-af02-28cf52914de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 3], dtype=torch.int32)\n",
            "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2886, 0.7114, 0.0000, 0.0000],\n",
            "         [0.3299, 0.4095, 0.2605, 0.0000],\n",
            "         [0.2985, 0.1735, 0.2143, 0.3137]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4326, 0.5674, 0.0000, 0.0000],\n",
            "         [0.3997, 0.1348, 0.4655, 0.0000],\n",
            "         [0.2500, 0.2500, 0.2500, 0.2500]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_k}})V$"
      ],
      "metadata": {
        "id": "aAJicY_pMkJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Scaled Self-Attention\"\"\"\n",
        "def scaled_dot_product_attention(Q, K, V, attn_mask):\n",
        "    score = torch.bmm(Q, K.transpose(-2, -1)) / torch.sqrt(model_dim)\n",
        "    masked_score = torch.masked_fill(score * attn_mask, -1e9)\n",
        "    prob = F.softmax(masked_score, -1)\n",
        "    context = torch.bmm(prob, V)\n",
        "    return context\n"
      ],
      "metadata": {
        "id": "0d3xYZgjKkH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**多头注意力**\n",
        "希望模型可以基于相同的注意力机制学习到不同的行为，然后将不同的行为作为知识组合起来，捕获序列内各种范围的依赖关系。\n",
        "可以独立学习得到h组不同的线性投影连变换Q,K和V。然后，这h组变换后的Q,K,V将并行送到注意力汇聚中。最后将这h个注意力汇聚的输出拼接在一起，并且通过一个可以学习的线性投影进行变换产生最终的输出。\n",
        "**自注意力机制**\n",
        "查询、键和值都来自于同一组输入。"
      ],
      "metadata": {
        "id": "V7TBbFvE3Nbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dKahB6TC0l8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}